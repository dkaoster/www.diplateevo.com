<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Diplateevo</title>
        <link>https://www.diplateevo.com</link>
        <description>A blog, by Daniel Kao</description>
        <lastBuildDate>Mon, 18 Apr 2022 17:37:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>SvelteKit</generator>
        <image>
            <title>Diplateevo</title>
            <url>https://www.diplateevo.com/cover-default.jpg</url>
            <link>https://www.diplateevo.com</link>
        </image>
        <copyright>Copyright 2022, Diplateevo</copyright>
        <atom:link href="https://www.diplateevo.com/rss.xml" rel="self" type="application/rss+xml"/>
        <item>
            <title><![CDATA[Data Journalism and the Digital News Era]]></title>
            <link>https://www.diplateevo.com/data-journalism-digital-news</link>
            <guid>https://www.diplateevo.com/data-journalism-digital-news</guid>
            <pubDate>Tue, 01 Mar 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[What is data journalism, and what role does it play in the future of the news industry?]]></description>
            <content:encoded><![CDATA[<p>By any honest reflection, journalism is a messy endeavor. It’s often a mad rush to publish while accounting for the demands of our sources, readers, and editors, creating an environment where being fever-pitched is more of a norm rather than an exception. Even in my corner of the newsroom doing data and graphics for news stories, the time constraints while collecting, transforming, analyzing, visualizing, editing, and optimizing digitally-interactive reporting leaves no time for pontification. No matter how restrictive these constraints are, I also find that some of the most creative and rewarding projects come out of this difficult and challenging environment.</p><p>In 2021 alone, I’ve worked with an extremely talented, cross-functional team to do everything from <a target="_blank" rel="noopener noreferrer" href="https://web.cw.com.tw/tra-train-crash/">3D recreations of news events</a> to <a target="_blank" rel="noopener noreferrer" href="https://web.cw.com.tw/solar-2020/index.html">digital cartography</a> to <a target="_blank" rel="noopener noreferrer" href="https://www.cw.com.tw/graphics/referendum-2021/">live elections</a>, <a target="_blank" rel="noopener noreferrer" href="https://web.cw.com.tw/covid-live-updates-2021-en/">COVID</a>, and <a target="_blank" rel="noopener noreferrer" href="https://web.cw.com.tw/drought-2021-en/index.html">drought trackers</a> in the form of breaking news and investigative journalism. We’ve had to use a non-trivial amount of software tools, open source libraries, and browser APIs, many for the first time. But no matter how much we improve our practice, there is always more to learn and new techniques to use. Being in the rapid development and publish cycle of a newsroom gives us the perfect environment to try all of these new tools and technologies in creative ways.</p><p>In 2021, we’ve also received significant recognition for our projects, <a target="_blank" rel="noopener noreferrer" href="https://www.cna.com.tw/project/thp_award/winners.html">winning news awards</a> and sharing our experiences with students and faculty at universities across Taiwan. The lessons and ideas discussed in this post are an adaptation of the talks I’ve given and feedback I’ve received in the past year at universities and other venues.</p><h2 id="data-visualization">Data Visualization</h2><p>But before I get to data visualization and graphics in a journalism context, I want to explore both data visualization and journalism separately, as many of our practices in data journalism are influenced by the broader context of the history as well as the current state of data, technology, and journalism. Many other industries have their own manifestations of data analysts and data visualizations, often using a very different set of tools and procedures than the ones we use in the newsroom.</p><h3 id="florence-nightingale">Florence Nightingale</h3><div class="image-wrap full svelte-5nv82e"><img loading="lazy" alt="Florence Nightingale" src="https://www.diplateevo.com/images/2022/03/nigtingale.jpg" width="100%" class="svelte-5nv82e">  </div><p>One of the earliest recorded examples of data visualization comes from the 1860s. <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Florence_Nightingale">Florence Nightingale</a>, often referred to as the “founder of modern nursing”, is more often recognized for her contributions to medicine and sanitation, but Nightingale was also a statistician, social reformer, and writer.</p><p>During the Crimean War, Nightingale took care of wounded soldiers and collected data on the situation in hospitals including death rates, sanitary conditions, and more. With this data, Nightingale eschewed the standard practice of simply printing the data on a table and visualized the situation in a revolutionary new way at the time: <a target="_blank" rel="noopener noreferrer" href="https://99percentinvisible.org/episode/florence-nightingale-data-viz-pioneer/">a radial pie chart</a>.</p><div class="image-wrap  svelte-5nv82e"><img loading="lazy" alt="Florence Nightingale&#39;s Chart" src="https://www.diplateevo.com/images/2022/03/nightingale-chart.jpg" width="100%" class="svelte-5nv82e">  </div><p>Doing so caught the attention of both fans and critics, but as a result of Nightingale’s research and publication, nursing made significant advancement toward the understanding of sanitation in healthcare, significantly reducing the mortality rate of wounded soldiers. In fact, this research would also provide grounds for improving sewage and sanitation in private homes, leading the way for significantly improved public health and sanitation. Nightingale’s work is inspiring not only because of the new visualization techniques she created, but also the impact she had on so many lives as a result of her research and publication methods.</p><h3 id="as-we-may-think">As We May Think</h3><p>In 1945, The Atlantic published <a target="_blank" rel="noopener noreferrer" href="https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/">“As We May Think” by Vannevar Bush</a>, an American engineer with dreams for &quot;a future device for individual use ... a sort of mechanized private file and library.” Bush called this conceptual device a “Memex” and goes on to describe in rough terms the internet-connected computers and mobile devices that everyone uses today.</p><blockquote><p>“Logic can become enormously difficult, and it would undoubtedly be well to produce more assurance in its use. The machines for higher analysis have usually been equation solvers. Ideas are beginning to appear for equation transformers, which will rearrange the relationship expressed by an equation in accordance with strict and rather advanced logic. Progress is inhibited by the exceedingly crude way in which mathematicians express their relationships.”</p></blockquote><p>Bush envisioned a future where these “memex” devices would significantly reduce the trivial limitations of physical mediums to help humans think in ways more conducive to conducting research, inventing new technologies, and living healthily. Bush envisioned much of the “information society” that we find ourselves in today, and took the optimistic view that such a society would be able to better solve scientific problems and understand history.</p><div class="image-wrap  svelte-5nv82e"><img loading="lazy" alt="A visualization of the Memex" src="https://www.diplateevo.com/images/2022/03/memex.jpg" width="500" class="svelte-5nv82e">  </div><p>Yet in other ways, the digital mediums we use today for data visualization are nowhere near the utopia that Bush dreamed of. Bret Victor talks about the still-unrealized potential that our media has on helping us <a target="_blank" rel="noopener noreferrer" href="http://worrydream.com/MediaForThinkingTheUnthinkable/">think thoughts that would be otherwise unthinkable</a>, and from a bird’s eye view is the big overarching challenge to everyone who does data visualization. Giorgia Lupi, an information designer that has spent a lot of time working to humanize data, <a target="_blank" rel="noopener noreferrer" href="http://giorgialupi.com/data-humanism-my-manifesto-for-a-new-data-wold/">talks about this challenge</a> in a very poignant way.</p><blockquote><p>“We have to find new languages, and explore how to convey knowledge and inspire feelings simultaneously with data. We have to discover how to be faithful to scientific accuracy while allowing space for exceptions to flourish. We have to bring data to life—human life.”</p></blockquote><h3 id="d3-and-the-web">D3 and the Web</h3><p>That brings me to our modern era of data visualization on the web. In 2011, Mike Bostock released <a target="_blank" rel="noopener noreferrer" href="https://d3js.org/">D3</a>, an open source library for creating graphics on the web. While D3 wasn’t the first data visualization library to be created for web browsers, it’s low-level approach and direct manipulation of the document object model (DOM) in web browsers allowed it to be incredibly flexible and adaptable to any kind of chart authors wanted to create.</p><p>Linking data directly with the low-level building blocks of the DOM unlocked a huge range of user interactions and visual animation. Compared to other programming languages used for data analysis such as Python or R, Javascript suddenly became an increasingly viable and attractive tool for data visualization because of its integration with web browsers and their native APIs such as HTML, CSS, and SVG. Since then, the Javascript ecosystem has exploded with tools and libraries for data visualization, including everything from managed services such as <a target="_blank" rel="noopener noreferrer" href="https://www.datawrapper.de/">Datawrapper</a> and <a target="_blank" rel="noopener noreferrer" href="https://www.tableau.com/">Tableau</a> to GPU-accelerated tools such as <a target="_blank" rel="noopener noreferrer" href="https://p5js.org/">P5</a> and <a target="_blank" rel="noopener noreferrer" href="https://regl-project.github.io/regl/">Regl</a> to 3D tools such as <a target="_blank" rel="noopener noreferrer" href="https://threejs.org/">Three.js</a> and so much more.</p><p>Additionally, web cartography has also experienced a renaissance of sorts. <a target="_blank" rel="noopener noreferrer" href="https://earth.google.com">Google Earth</a> and <a target="_blank" rel="noopener noreferrer" href="https://www.google.com/maps">Google Maps</a>, two of the most established consumer digital cartography products in the internet era, have become increasingly similar as web browsers have become powerful enough to run the features that would previously only run on standalone applications such as Google Earth. The possibilities for creating complex, geographically detailed, or interactive data explorations accessible to anyone with a web browser would have been unfathomable when D3 first launched in 2011.</p><div class="image-wrap  svelte-5nv82e"><img loading="lazy" alt="ObservableHQ homepage" src="https://www.diplateevo.com/images/2022/03/observable.png" width="100%" class="svelte-5nv82e">  </div><p>Today, Bostock is working full-time on <a target="_blank" rel="noopener noreferrer" href="https://observablehq.com/">Observable</a>: an environment for collaborative, visual, and explanatory notebooks that run locally in the browser. The ability to browse, remix, and adapt notebooks other people have written has given individuals learning to do data visualization an easy way to publish standalone graphics and interactives. Tools like Observable are an example of the ways that web browsers continue to evolve to support new features, even if they are incremental improvements on existing technologies, rather than hype-fueled fads.</p><h2 id="journalism">Journalism</h2><p>When it comes to newsrooms, however, the transition into the digital era has not been at all smooth. In the late 2000s, a wave of digitally-native platforms arose in competition to the long-standing industry of established newspapers and magazines, followed by another wave of social media startups awakening to monetize the attention of internet users, eating away both both the discovery channels and advertising revenue of the existing media industry.</p><div class="image-wrap  svelte-5nv82e"><img loading="lazy" alt="David Carr and Vice News" src="https://www.diplateevo.com/images/2022/03/carr-vice.jpg" width="100%" class="svelte-5nv82e">  </div><p>Tech companies, media leaders, advertising companies, and internet users all had—and still have, competing visions of what journalism on the internet should look like. Vice News, one manifestation of digital-native news organizations, took a very raw and borderline sensational approach to telling stories. David Carr, the former media critic at The New York Times, <a target="_blank" rel="noopener noreferrer" href="https://www.nytimes.com/2010/02/15/business/media/15carr.html">wrote in his column</a> his observations about Vice News.</p><blockquote><p>“The company has grown to 560 employees in 30 countries, with 2,500 freelancers who are mostly paid in hipster cred. This success has created some dissonance for a crew of raconteurs who have spent much of their lives laughing at the stiffs who live pointless lives in dumb jobs defined by their next PowerPoint presentations.”</p></blockquote><p>Beneath the past two decades of media debates and debacles has ultimately been the loss of trust in media. Sensational clickbait headlines, deceptive subscription packages, partisan politicization, fake news, poor user experience, lack of cultural, gender, or racial sensitivity, sponsored content, have all contributed to the precipitous drop in the public’s journalistic trust.</p><h3 id="the-kerner-commission-50-years-later">The Kerner Commission, 50 Years Later</h3><div class="image-wrap full svelte-5nv82e"><img loading="lazy" alt="Kerner Commission" src="https://www.diplateevo.com/images/2022/03/kerner.jpg" width="100%" class="svelte-5nv82e">  </div><p>While most of these are not unique to the internet era, the internet era has made a lot of these problems a lot more apparent. Back in 1968, <a target="_blank" rel="noopener noreferrer" href="https://www.nytimes.com/2020/06/23/us/kerner-commission-report.html">the Kerner Commission</a> surfaced all sorts of racial injustices, including the media industry’s lack of diversity for the racial riots happening in America. Reading a report from over fifty years ago reveals how little has changed, and how many of its criticisms still ring true today.</p><blockquote><p>“the press has too long basked in a white world looking out of it, if at all, with white men’s eyes and white perspective. That is no longer good enough. The painful process of readjustment that is required of the American news media must begin now.”</p></blockquote><p>There often is a real disconnect between the lofty ideals espoused by media executives and the realities of the work being done. They tell you “Journalism is what we need to make democracy work” or “News organizations hold truth to power”, but fail to hire and retain a diverse workforce themselves. Even some of the most high-profile instances in recent years have showcased the conflicts between news executives and their workforces, such as The New York Times using shady strategies to <a target="_blank" rel="noopener noreferrer" href="https://www.theguardian.com/media/2022/feb/01/leaked-messages-new-york-times-anti-union-strategy">prevent their technologists from unionizing</a>.</p><p>This is in addition to all the challenges that news organizations have in finding and retaining diverse talent. In an <a target="_blank" rel="noopener noreferrer" href="https://source.opennews.org/articles/exit-interviews-aaron-williams/">exit interview with Source</a>, Aaron Williams talks about the artificial ceiling he experienced as a data journalist, and even the shame he felt when he left The Washington Post for a job at Netflix.</p><blockquote><p>“Being labelled a ‘digital’ journalist felt like death knell to my future career aspirations. I spent large parts of my career convincing editors I was a journalist, full stop, and that the data and design aspects of my skill set aided in that endeavor.”</p></blockquote><p>Of course, journalism isn’t the only industry challenged by instances of poor management and unhealthy work cultures. However, the role of the news industry in our modern society and the lofty values espoused as a check on power lends the news industry to a higher standard and far more scrutiny, in ways that news organization need to approach with transparency and leadership. Some of the harshest scrutiny of news organizations can be found on social media, another deeply integral phenomenon of our digital era.</p><h3 id="social-media-and-seo">Social Media and SEO</h3><p>Social media has, on one hand, become vital distribution channel for news organizations, but on the other hand, left news organizations at the mercy of opaque social media algorithms whose sole purpose is to maximize engagement. When social media platforms announced a “<a target="_blank" rel="noopener noreferrer" href="https://www.vanityfair.com/news/2018/10/was-the-medias-big-pivot-to-video-all-based-on-a-lie">pivot to video</a>” in 2015, news organizations had little choice but to follow along, forced to accept what later was revealed to be fake viewership metrics just to appease advertisers.</p><p>Even today, the relationship between social media platforms and news organizations remains tenuous at best. Also launched in 2015, <a target="_blank" rel="noopener noreferrer" href="https://www.facebook.com/formedia/tools/instant-articles">Facebook Instant Articles</a> is a way for Facebook to collaborate with publishers, allowing news articles to be easily and efficiently readable directly on Facebook without users ever having to leave the app or the website. Much like Facebook&#39;s push for video, instant articles has been <a target="_blank" rel="noopener noreferrer" href="https://www.cjr.org/tow_center/are-facebook-instant-articles-worth-it.php">largely abandoned</a>, due to the lack of results and loss of control for publishers.</p><p>Search engines, in a similar vein, have also attempted to strong-arm publishers into playing by their rules. Google released <a target="_blank" rel="noopener noreferrer" href="https://developers.google.com/amp/">Accelerated Mobile Pages</a> (AMP) in 2015 promising a better and faster experience for mobile users by using a customized set of amp-compatible HTML. And while AMP did in fact improve page-load times for many news articles, AMP also had scandals such as <a target="_blank" rel="noopener noreferrer" href="https://www.theregister.com/2021/10/26/google_deliberately_throttled_ad_load/">throttling non-AMP ads</a> in order to promote AMP. And as search engine optimization has taken off as its own sub-industry under marketing departments, search engine results are quickly becoming a listing of who has money to hire SEO specialists rather than who actually has the best content.</p><h3 id="the-challenge-inside-newsrooms">The Challenge Inside Newsrooms</h3><div class="image-wrap full svelte-5nv82e"><img loading="lazy" alt="Newspaper printer" src="https://www.diplateevo.com/images/2022/03/print.jpg" width="100%" class="svelte-5nv82e">  </div><p>One of the largest shifts within newsrooms, however, has been the diversification of roles and responsibilities, no longer comprised of only the journalists, editors, and photographers of yesteryear. Today, newsrooms include roles such as podcasters, video editors, project managers, designers, software engineers, cartographers, data scientists, and so many more. The scope of an entire news product has ballooned far beyond what any single person or leadership unit can possibly grasp.</p><p>This means that traditional, hierarchical management structures are ill-suited to adapt to the complexities and challenges of the modern digital journalism, especially if a newsroom has aspirations of publishing across a diversity of print, video, audio, and digital formats. The New York Times&#39; <a target="_blank" rel="noopener noreferrer" href="https://www.nytimes.com/projects/2020-report/index.html">2020 Report</a> talks about this challenge.</p><blockquote><p>“We need to become more comfortable with our photographers, videographers and graphics editors playing the primary role covering some stories, rather than a secondary role.”</p></blockquote><p>According to the recently released <a target="_blank" rel="noopener noreferrer" href="https://datajournalism.com/survey/2021/">State of Data Journalism Survey</a> conducted by the European Journalism Centre, most data journalists are still siloed in their own “data units”, with <a target="_blank" rel="noopener noreferrer" href="https://datajournalism.com/survey/2021/work-practices/">infrequent collaboration</a> with other people in their newsrooms. Journalists are unsure how to work with technologists, often creating an environment where different factions form within newsroom, rather than playing on a diversity of skills and approaches in telling stories.</p><h2 id="the-future-of-data-and-visual-journalism">The Future of Data and Visual Journalism</h2><div class="image-wrap full svelte-5nv82e"><img loading="lazy" alt="Data Journalism Projects at Commonwealth Magazine" src="https://www.diplateevo.com/images/2022/03/data-journalism-projects.jpg" width="100%" class="svelte-5nv82e">  </div><p>With ever-advancing digital mediums and all the challenges facing journalism, there is a significant opportunity to rethink our relationship with news, especially given the world of data that we live in. From a data and technology perspective, there has never been a better time to do journalism, only limited by how we adapt and use more data and technology in our reporting. This is not to say we ignore the lessons of the previous era of physical media, but rather how we build upon the lessons of the past using the tools of the present, in close collaboration with traditional journalists and editors.</p><p>Over the past two years, we’ve seen the COVID-19 story create a whole new class of long-lived data journalism projects that have challenged the traditional notion of what a story is. How a project gets updated, edited, and shared has now become an important consideration for large-scale projects that aim to help readers understand a situation. This model can be extended to other areas to help the public better understand nuances of natural phenomena, government policies, social phenomena, climate change, economic cycles, and so much more.</p><p>This is an exciting shift in journalism because it helps organizations report news beyond units of stories or articles, allowing news organizations to better capture and track long-running stories and trends. Another benefit of doing so is helping readers become more familiar with data-driven approaches, allowing interactive visualizations to serve both explanatory and exploratory roles.</p><h3 id="big-macs-and-open-data">Big Macs and Open Data</h3><p>The <a target="_blank" rel="noopener noreferrer" href="https://www.economist.com/big-mac-index">Big Mac Index</a> by The Economist is also a great example of this kind of long-running data journalism project. Invented in 1986 as a “lighthearted guide to whether currencies are at their ‘correct’ level”, the Big Mac Index has been quoted in numerous academic studies due to how easy it is to understand and digest. Additionally, the data behind the Big Mac Index, is <a target="_blank" rel="noopener noreferrer" href="https://github.com/TheEconomist/big-mac-data">available on Github</a> under an open source MIT license, freely available for anyone to use for any purpose.</p><p>Releasing open data to the public is another way of sharing stories in our digital society. News organizations have the opportunity to not only look for data to tell stories with, but also the opportunity to be contributors of data. A few examples of this include The Washington Post releasing data on <a target="_blank" rel="noopener noreferrer" href="https://www.washingtonpost.com/graphics/investigations/police-shootings-database/">police shootings in the US</a>, The New York Times making <a target="_blank" rel="noopener noreferrer" href="https://github.com/nytimes/covid-19-data">COVID datasets public</a>, or ProPublica’s <a target="_blank" rel="noopener noreferrer" href="https://projects.propublica.org/api-docs/congress-api/">Congress API</a>.</p><p>I believe that, if done responsibly, data journalism can play a significant role in helping restore the public’s trust in media. By making data public and contributing to the world of open data, news organizations can also help bolster public trust, transparency, and data literacy. Despite the fact that only a small subset of readers may download the data themselves, releasing data ultimately allows for greater accountability within the stories we are reporting on.</p><h3 id="the-digital-newsroom">The Digital Newsroom</h3><p>This is not to say that visual, web-based journalism is the only innovation happening in the journalistic sense. Podcasts are reaching audiences that traditional words and pictures have been unable to reach, creating a whole new segment and conventions around telling stories through audio. Online video journalism, despite Facebook’s “pivot to video” scam of last decade, is still a viable and growing area. There are synergies yet to be explored between all of these differing mediums of journalism and fully realized in reporting.</p><p>Experimentation, prototyping, and rapid feedback loops are vital parts of successful digital newsrooms. Just as journalists must often adapt to the specific circumstances of a political system, industry, or environment in order to properly and ethically report on it, newsrooms must learn to be flexible enough to adapt to the trends in technology and readership in order to better tell stories. Mediums such as virtual or augmented reality, video games, social media, are all potential areas to be carefully considered and experimented with in future iterations of news products.</p><p>In conclusion, it’s easy to become infatuated with the pace new technologies are being developed and deployed, but news organizations need to remain focused on their north star of telling stories that matter using data, visuals, or other multimedia when it strengthens stories. News organizations have the opportunity to play a larger role in making data more accessible and transparent to the public, while simultaneously working to improve data literacy as much as possible. It’s a challenge that will continue to be messy and challenging to manage, but I believe that newsrooms can continue to be vital institutions of leadership and innovation.</p>]]></content:encoded>
            <enclosure url="https://www.diplateevo.com/images/2022/03/data-journalism.jpg" length="0" type="image/jpg"/>
        </item>
        <item>
            <title><![CDATA[Why You Should Use ArchieML for Your Blog]]></title>
            <link>https://www.diplateevo.com/archieml</link>
            <guid>https://www.diplateevo.com/archieml</guid>
            <pubDate>Fri, 04 Feb 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[It’s easy to go from structured data to unstructured data, but trying to go the other way is a losing, uphill battle.]]></description>
            <content:encoded><![CDATA[<p>If you’ve spent any time with static site generators such as <a target="_blank" rel="noopener noreferrer" href="https://gohugo.io/">Hugo</a>, <a target="_blank" rel="noopener noreferrer" href="http://jekyllrb.com/">Jekyll</a>, or <a target="_blank" rel="noopener noreferrer" href="https://www.gatsbyjs.com/">Gatsby</a>, you’ve probably used <a target="_blank" rel="noopener noreferrer" href="https://daringfireball.net/projects/markdown/">markdown</a> or <a target="_blank" rel="noopener noreferrer" href="https://mdxjs.com/">mdx</a>. The benefits of using markdown are immediately apparent from the very minimal markup required to add titles, links, bullet points, and various other text formatting options in a plain-text file. Additionally, many implementations of markdown such as <a target="_blank" rel="noopener noreferrer" href="https://github.github.com/gfm/">GitHub flavored markdown</a> allows HTML to be directly embedded into markdown, giving additional flexibility when the primitives of markdown don’t allow for enough versatility.</p><p>However, using markdown files for blog posts reveals a problem. Markdown, like HTML, is unstructured. (Technically HTML is considered “semi-structured”, but that distinction is irrelevant to the discussion in this post) In more tangible terms, there’s no way to explicitly provide SEO tags such as a title or a feature image or any other kind of structured key-values into a blog post with plain markdown. That’s why <a target="_blank" rel="noopener noreferrer" href="https://mdxjs.com/">mdx</a> was created, with a section at the top called <a target="_blank" rel="noopener noreferrer" href="https://mdxjs.com/guides/frontmatter/">frontmatter</a> which allows structured data with a YAML syntax, try it below.</p><pre>This component is not available in RSS. To view, please open this page in a web browser.  </pre><p>With frontmatter, there are two distinct sections of markdown files: a structured YAML section and a separate section for unstructured data written in markdown or HTML down below. For simple content structures and blogs, this is sufficient. For more complex visual components interleaved inside of content, however, using mdx will create a mess of HTML and CSS abstractions leaking out all over the markdown files, making it brittle, hard to understand, and a pain to update. Even using custom components the way that <a target="_blank" rel="noopener noreferrer" href="https://www.gatsbyjs.com/docs/how-to/routing/mdx/">Gatsby defines in their documentation</a>, stuffing data into HTML/JSX style syntax is possible, but cumbersome and not ideal.</p><p>In my career as a graphics journalist, I’ve seen this problem come up over and over again. Making interactive articles in collaboration with a team of journalists, editors, and designers, the complexities of our articles and interactives coupled with the workflow we use to ensure that everyone can work effectively in parallel means that using purely markdown to manage content is untenable.</p><p>Instead, we use <a target="_blank" rel="noopener noreferrer" href="http://archieml.org/">ArchieML</a>, a structured data markup language that has been widely adopted by newsrooms that make these kinds of interactive articles, but lesser known to the broader ecosystem of bloggers and web developers. After using ArchieML for the past three years at work, I have found that the ways that it can be used and adapted are far more suitable than mere markdown, and I’ve completely rebuilt this site’s static site generator to use ArchieML files. In fact, the blog you are reading uses ArchieML and markdown together, because with a few important exceptions, ArchieML and markdown do not conflict with each other.</p><h2 id="archieml">ArchieML</h2><p>ArchieML is named after <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/archietse">Archie Tse</a>, the current graphics director at The New York Times. ArchieML’s syntax is, like markdown’s, very succinct and unobtrusive, but also provides advantages over YAML or JSON when it comes to structured data. From the ArchieML documentation:</p><ul><li><strong>Whitespace is not significant to the document structure</strong> In YAML, lines must be indented precisely and variably; the wrong number of spaces to the left of a key invalidates the document, and tabs can&#39;t be used. AML ignores all whitespace not within a value. We believe this makes it easier for non-programmers to use, and is essential for use in environments with non-monospaced fonts, like in Google Documents.</li></ul><ul><li><strong>Unstructured text is ignored; there is no such thing as a parsing error</strong> AML was designed so that writers could work in a freeform environment. They should be able to add entire paragraphs as scratch work that do not appear in the output. JSON and YAML have strict schemas that forbid text deviating from a pattern. AML doesn&#39;t assume text follows any pattern. If it finds text that looks like data, it treats it as data. Otherwise, it moves on.</li></ul><ul><li><strong>The notation makes sense to non-programmers</strong> Lists of values are noted with bullet points / asterisks, not hyphens or quoted strings that must be separated with commas. An overriding goal was to have an intuitive format that could be passed to a non-technical user — a reporter, an assigning editor or a copy editor — to edit, and to have the format be clear enough that they could make changes without breaking the parsing of the document. If we were using another format, we&#39;d have to explain indentation rules in YAML, or how to match curly braces or properly escape quotation marks in JSON, and so forth.</li></ul><p>From ArchieML’s documentation page, The New York Times uses ArchieML <a target="_blank" rel="noopener noreferrer" href="https://github.com/newsdev/archieml-js/tree/master#using-with-google-documents">in conjunction with Google Docs</a> to allow editors to easily update and collaboratively work on interactive graphics, but the ArchieML specification can be used anywhere, not just on Google Docs.</p><p>This is what ArchieML looks like in practice, try it below:</p><pre>This component is not available in RSS. To view, please open this page in a web browser.  </pre><h2 id="keep-content-structured">Keep Content Structured</h2><p>One thing that isn&#39;t talked about enough in web development is that it’s easy to go from structured data to unstructured data, but trying to go the other way is a losing, uphill battle. Most content management systems for blogs, websites, or other personal pages work by having a backend with a <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/WYSIWYG">WYSIWYG</a> editor that generates some kind of HTML that then gets stuffed in between some kind of content wrapper inside the final HTML of the web page. This means that the final webpage’s HTML is generated in two separate places: the editor generates HTML that is wrapped by HTML generated by the theme, which blindly applies CSS to the HTML generated from the editor in hopes that everything works properly.</p><p>In this case, adding custom elements becomes bespoke and unwieldy as custom CSS either gets mixed into the editor’s HTML or custom overrides and HTML parsing hacks get written into the frontend logic. In either case, the frontend and the content cease to operate independently of each other, causing future migrations or site redesigns to become a nightmare.</p><p>A much better approach is to structure content into blocks, giving each block of content its own type and allowing the front-end to have more context on how that block should be rendered. This means that instead of the editor spitting out a block of spaghetti HTML that simply gets blindly embedded into some spot on the page, the editor spits out an array of content that contains blocks for the front-end to iterate over. This allows the editor to generally be more free of display logic specifics (sometimes it can&#39;t be avoided), handing over all of that responsibility to the frontend where it belongs.</p><p>While there are open source WYSIWYG editors such as <a target="_blank" rel="noopener noreferrer" href="https://draftjs.org/">draft.js</a> or <a target="_blank" rel="noopener noreferrer" href="https://prosemirror.net/">prosemirror</a> that allow users to create content in a structured way, neither markdown nor mdx allow for this kind of flexibility in a plain-text format. That’s where ArchieML fits in.</p><h2 id="archieml--markdown--😍">ArchieML + Markdown = 😍</h2><p>As I alluded to above, ArchieML can be used in conjunction with markdown for some extremely powerful results. The trick here is to parse a document in ArchieML first by putting all the content inside a freeform array, and then parse individual blocks as markdown in order to get the full flexibility of structured and minimalistic text formatting. In fact, all the posts on this blog are structured in this way, you can <a target="_blank" rel="noopener noreferrer" href="https://github.com/dkaoster/www.diplateevo.com/blob/main/content/archieml.txt">see the file for this post here</a>.</p><p>The caveat is that because ArchieML has parsing logic around newlines, multi-line markdown tags such as lists or tables will not be parsed properly if used directly. Thus, these will have to be wrapped and escaped in a way that ArchieML will ignore the line breaks.</p><pre>This component is not available in RSS. To view, please open this page in a web browser.  </pre><p>The result is a plain-text markup and formatting specification that is far more flexible than mdx, and allows content and display logic to be defined and maintained in a much more manageable way. There’s a reason the New York Times created ArchieML for graphics, and the wider internet community can take advantage of it in a similar way.</p>]]></content:encoded>
            <enclosure url="https://www.diplateevo.com/images/2022/02/archieml.png" length="0" type="image/png"/>
        </item>
        <item>
            <title><![CDATA[I'm Reviving this Blog in 2022]]></title>
            <link>https://www.diplateevo.com/looking-to-2022</link>
            <guid>https://www.diplateevo.com/looking-to-2022</guid>
            <pubDate>Fri, 14 Jan 2022 00:00:00 GMT</pubDate>
            <description><![CDATA[Forget web3, I'm going back to web 1.0.]]></description>
            <content:encoded><![CDATA[<p>When I started this blog back in high school, a classmate of mine kindly gave me access to his web host and a WordPress sandbox and let me do whatever I wanted. I started hacking my way around HTML, CSS, PHP, and MySQL, finding a way to break this website almost weekly and trying out as many WordPress plugins and themes as I possibly could. I flouted my parents&#39; computer use curfew by waking up at six in the morning in order to play with my website (or computer games), and the name &quot;diplateevo&quot; came out of an experiment rearranging random letters until I got something unique.</p><p>I started blogging regularly and soon outgrew my borrowed web host. After a few conversations with my father, he agreed to pay for shared hosting on Dreamhost, and I continued developing and vastly overcomplicating my WordPress installation. By the time I graduated college, however, I started working full-time and blog updates became infrequent. I started using Twitter regularly as a way to share my thoughts and connect with people around the world. In fact, part of my decision to ultimately move to Taiwan was spurred by conversations with people I met through Twitter.</p><p>Eventually, I wondered why I was paying nearly $30 a month to host this website that I barely used, and decided to greatly simplify and re-engineer this blog to use a gerry-rigged <a href="https://ghost.org/" target="_blank" rel="noopener noreferrer">Ghost CMS</a> to serve as a static site generator with a frontend written in <a href="https://svelte.dev/" target="_blank" rel="noopener noreferrer">Svelte</a> and <a href="https://sapper.svelte.dev/" target="_blank" rel="noopener noreferrer">Sapper</a>, hosted on <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">Github Pages</a>. Hosting costs went to zero, but this blog continued to be dormant.</p><p>My optimism toward social media started going downhill sometime around 2015-2016. It’s hard to pinpoint an exact inflection point, but around that time I started noticing people around me getting information more from internet sources rather than from books, magazines, and newspapers. The explosion of the mobile internet and “the sharing economy” meant that a significant amount of people had their first experience with the web not in the Web 1.0 era, but in the Web 2.0 era on mobile devices.</p><p>Ironically, that was when I first started playing with cryptocurrencies and still optimistic about what changes blockchains might bring to our digital lives. No one knew at the time that Bitcoin was going to reach the valuation it has today, and the mere possibility that it might end up completely worthless is exactly what made it fun, interesting, and worthwhile. The entire experience felt like the alpha release of a cool, low-risk, tech product that I could experiment with. It’s unfortunate that in 2022, it still feels like an alpha product and yet is no longer anywhere near low-risk.</p><h2 id="decentralized-mistrust">Decentralized Mistrust</h2><p>Today, it’s impossible to scroll through my Twitter feed or browse Hacker News without someone arguing about cryptocurrencies, Web3, or the metaverse, espousing ideals about “decentralization” without fully understanding what it means. I want to get away from predatory social media and advertising platforms as much as anyone, but most blockchain applications feel like a frankenstein solution forced onto a problem they were never meant to solve.</p><p>To put it simply, blockchains allow individuals to cooperate with others they don’t trust by placing trust in the network and cryptographic algorithms securing the data. This as an incredible engineering feat and certainly has valuable and appropriate use cases. But just as driving an armored vehicle with a motorcade is overkill and cost / energy inefficient for most transit scenarios, moving all our applications onto blockchain-powered platforms is not going to solve any real problems while only creating more problems. For example, how is a blockchain-powered social media platform going to be any better at solving harassment problems, especially if every single post gets written permanently on-chain? Without any cooperation with legally enforceable regulations, how are so called “smart contracts” going to provide any jurisdiction over the real world?</p><p>Additionally, blockchain protocols are built with mistrust as a default state, which means a lot of redundant energy is spent verifying every single transaction, which is why cryptocurrencies consume exorbitant amounts of energy in return for little actual performance, not to mention the extra amount of engineering required to build, deploy, and support something on the blockchain.</p><h2 id="a-new-old-vision-for-diplateevo">A New (Old) Vision for Diplateevo</h2><p>All that to say, I will not be web3-ifying Diplateevo (whatever that means) anytime soon. As someone who has built a career in frontend engineering, I’ve started to really value simplifying things as much as possible, and creatively thinking about ways to make software more resilient, reliable, and performant. I find that my most productive programming sessions are when I delete more code and write more testing and documentation, because it allows me to rethink and triple check my output.</p><p>I’ve re-engineered this website (yet again) to be even simpler and portable, and have even decided to <a href="https://github.com/dkaoster/www.diplateevo.com" target="_blank" rel="noopener noreferrer">make the whole thing public</a>. It’s still built on <a href="https://svelte.dev/" target="_blank" rel="noopener noreferrer">Svelte</a>, but I’ve migrated to <a href="https://kit.svelte.dev/" target="_blank" rel="noopener noreferrer">SvelteKit</a> and removed Ghost CMS backend in favor of simple <a href="http://archieml.org/" target="_blank" rel="noopener noreferrer">ArchieML</a> text files to generate a static website. This will allow me the flexibility to do both simple and complex posts, which I plan to do a lot more of in 2022.</p><p>Web 1.0 ftw.</p>]]></content:encoded>
            <enclosure url="https://www.diplateevo.com/images/2022/01/cover-2022.jpg" length="0" type="image/jpg"/>
        </item>
        <item>
            <title><![CDATA[Building a Realtime Election Tracker]]></title>
            <link>https://www.diplateevo.com/building-a-realtime-election-tracker-for-taiwans-2020-election</link>
            <guid>https://www.diplateevo.com/building-a-realtime-election-tracker-for-taiwans-2020-election</guid>
            <pubDate>Wed, 29 Jan 2020 00:00:00 GMT</pubDate>
            <description><![CDATA[On January 11th, 2020, Taiwan went to the polls to elect their next President and Legislature. For us at the News Lens, we formed a small team of designers, engineers, and editors to build this year’s election tracker.]]></description>
            <content:encoded><![CDATA[<p>On January 11th, 2020, Taiwan went to the polls to elect their next President and Legislature. In Taiwan’s short history as a democracy, this election was only the 7th presidential election that Taiwan has held, conducted after months of unrest in Hong Kong and an increasing trend of populism around the world. For us at <a target="_blank" rel="noopener noreferrer" href="https://international.thenewslens.com/">the News Lens</a>, we formed a small team of designers, engineers, and editors to build <a target="_blank" rel="noopener noreferrer" href="https://international.thenewslens.com/interactive/126882">this year’s election tracker</a>.</p><h2 id="product">Product</h2><p>Before we started planning the technical details, we began by thinking about election coverage as a product: What do readers care about? What are their reading habits / usage patterns? Who is our audience?</p><div class="image-wrap full svelte-5nv82e"><img loading="lazy" alt="screenshots of different devices" src="https://www.diplateevo.com/images/2020/08/Artboard-2.png" width="100%" class="svelte-5nv82e">  </div><p>For starters, we expected that 80% of our readers would be accessing our content from a mobile device, and the large majority would be looking for Chinese content, although we would also make a version for our English readers. We knew that we wanted to display the results as close to realtime as we possible could, and knew that we wanted to cover presidential, district legislators, party legislators, and indigenous legislators. We also knew that we wanted to create an experience that gave readers content for before, during, and after the election, and to make content that could be built upon and referenced in the future.</p><div class="image-wrap  svelte-5nv82e"><img loading="lazy" alt="presidential poll tracking" src="https://www.diplateevo.com/images/2020/08/Screenshot-2020-01-24-14.34.45.png" width="100%" class="svelte-5nv82e">  </div><p>To begin, we launched our election coverage by doing an aggregation of political polls in Taiwan, giving readers a more holistic view of trends of support for each of the presidential candidates. This not only gave us a way to promote our election coverage, but also gave us a way to test our new, Svelte-based system for building interactive articles and work out some of the kinks before election day. In total, building this tracker took us about two months, with a dedicated engineer and designer working nearly full time on this project.</p><h2 id="maps">Maps</h2><p>Given that the main interaction users make with the election tracker is through the map, the map had to be responsive to user interaction and data updates. To allow users to explore as much of the data as possible, we decided that our map would at have three different layers to interact with.</p><p>The topmost layer is the whole country, including the outer islands that are part of Taiwan’s jurisdiction, followed by 22 counties (縣市). Each of the 22 counties can be further divided into towns (鄉鎮區), and the smallest unit of locality which we did not display is the village (里).</p><p>All of this map data is obtained from <a href="https://data.gov.tw/dataset/7438" target="_blank" rel="noopener noreferrer">Taiwan’s government website</a> in the form of a 114MB shapefile. Obviously, if we were to directly convert the shapefile to topojson (a format for browsers to draw maps, more on this later), we’d still be looking at a file that is ~90MB in size; far too big to have every user download to their device.</p><p>Moreover, the map needs to be processed for special areas (areas that are part of Taiwan’s jurisdiction but may not be part of an official locality, such as 釣魚台) and relocation of the outer islands so that Kinmen and Lienchiang don’t make the map look too big. At first, I processed a few topojson files using QGIS and the shapefile obtained from the government, but after many failed attempts, (ie incorrect island relocation, missing districts, resulting file too large, too many details removed from the map during compression, etc) I decided to create an API endpoint that would process the map that I want on the fly.</p><div class="image-wrap full svelte-5nv82e"><img loading="lazy" alt="dynamic map generating code" src="https://www.diplateevo.com/images/2020/08/Artboard-8.png" width="100%" class="svelte-5nv82e">  </div><p>In essence, the API endpoint takes a few parameters:</p><ul><li>Map Version: Due to the fact that these borders will change based on redistricting or otherwise, I wanted to future-proof this API by allowing future maps to be easily versioned by year.</li><li>Locality Depth: Do we want the borders of the county, town, village, or district?</li><li>Specific Locality: Do we want the borders of a specific county, town, village, or district?</li><li>Simplification Level: How simplified do we want the resulting JSON file to be? More simplification and quantization means smaller file sizes but also a loss of detail.</li><li>Condensation of Outer Islands: Do we want a map where Kinmen and Lienchiang are where they are geographically or do we want to see them closer to mainland Taiwan?</li></ul><p>However, because legislative districts are not exactly correlated to any one of the existing locales, we had to separately process all of the locales of each of the legislative districts. Because a whole day of searching could not turn up a shapefile for Taiwan’s legislative districts, we decided to create the map ourselves based on which counties, towns, or villages, belonged to which district.</p><div class="image-wrap full svelte-5nv82e"><img loading="lazy" alt="custom map making" src="https://www.diplateevo.com/images/2020/08/Artboard-3.png" width="100%" class="svelte-5nv82e">  </div><h3 id="svg-vs-canvas">SVG vs Canvas</h3><p>After constructing a reliable way to generate our topojson, the next question was figuring out how to display it in our browser. The naive approach is to <a href="https://medium.com/@mbostock/command-line-cartography-part-1-897aa8f8ca2c" target="_blank" rel="noopener noreferrer">simply render the topojson to a SVG</a>. However, the problem with this is that SVGs use the DOM, which means that changes or user interactions with a complex SVG is slow and resource intensive. Add locale labels and mouse interactions and suddenly your SVG implementation slows to a crawl.</p><p>The alternative is to use a canvas for display and an invisible SVG for interaction. This allows us to avoid expensive DOM operations of maintaining and manipulating the color of each locale on the map and instead use the canvas API to paint our map, while maintaining a SVG just to keep track of when users interact. In my very unscientific benchmarking on my own machine, I found that SVGs needed to be about twice a simplified compared to canvas in order to achieve similar performance. More about <a href="https://observablehq.com/@rdmurphy/combining-html-canvas-svg-flatbush-for-super-efficient-hov" target="_blank" rel="noopener noreferrer">this method here</a>.</p><p>The optimizations that I could have done on the map are endless. If we were to further optimize the map, I would recommend using some kind of WebGL implementation, potentially <a href="https://docs.mapbox.com/mapbox-gl-js/api/" target="_blank" rel="noopener noreferrer">MapboxGL</a> to make map rendering performance even better, but a canvas approach was good enough for this use case.</p><h2 id="data-pipeline">Data Pipeline</h2><p>The data for our election tracker was obtained from the Central Election Committee, which gives us a 3MB JSON file of all the data anytime it is updated. Because this JSON file is so large and can take up to 5 seconds to download from the Central Election Committee, we decided to only fetch it at a regular cadence and process / store it into a database we can control and scale.</p><div class="image-wrap full svelte-5nv82e"><img loading="lazy" alt="data pipeline screenshot" src="https://www.diplateevo.com/images/2020/08/Artboard-9.png" width="100%" class="svelte-5nv82e">  </div><p>To do this, we used a cron job that would fetch the latest data from the Central Election Committee every minute, and separate out presidential and legislative results before storing it into Google Datastore.</p><p>Then, in order to indicate when a candidate has won, we connected a Google Spreadsheet that allowed our editors to manually mark when a race had been won. The system would then use that data to display the winner on the frontend. As it turns out, this became a problem on the night of the election, which I expand more on in the “lessons learned” section.</p><h2 id="election-rules-edge-cases">Election Rules Edge Cases</h2><p>In terms of electoral rules, Taiwan follows a simple majority-wins policy for electing it’s president, which is easy to display on a map. However, legislative races follow a fairly complex system:</p><ul><li>Taiwan’s legislature has a total of 113 seats.</li><li>73 district legislators are elected through a majority-wins policy for each of the 73 designated districts of Taiwan.</li><li>34 party legislators are elected through a party-vote system, in which voters vote on a party, and all parties that obtain over 5% of the overall vote get to assign legislators based on the proportion of votes they receive. The legislators of a party elected through this system must be &gt;50% female, according to the order they are ranked in their party list.</li><li>6 indigenous legislators are elected by two three-member constituencies, picking the top three legislators for each plains and highlands indigenous constituencies.</li></ul><div class="image-wrap  svelte-5nv82e"><img loading="lazy" alt="towns vs legislative districts" src="https://www.diplateevo.com/images/2020/08/Artboard-6.png" width="100%" class="svelte-5nv82e">  </div><p>This logic poses a few challenges. First of all, the topmost level we can display for district legislators is the district itself, because we can’t calculate the color for a county that has multiple districts with different races.</p><div class="image-wrap  svelte-5nv82e"><img loading="lazy" alt="legislative district colors" src="https://www.diplateevo.com/images/2020/08/Artboard-5.png" width="100%" class="svelte-5nv82e">  </div><p>Second, because indigenous legislature races elect the top three candidates for each plains and highlands indigenous groups, simply coloring a district with the party of the first-place candidate does not reflect the true breakdown of the vote. Thus, we decided to take the top three candidates and add up the votes based on their political parties, then take the color of the party with the most votes.</p><div class="image-wrap  svelte-5nv82e"><img loading="lazy" alt="party vote order" src="https://www.diplateevo.com/images/2020/08/Artboard-4.png" width="100%" class="svelte-5nv82e">  </div><p>Third, because of the gender rule for party votes, legislators of a party that get elected through this method do not necessarily correspond with the order that they are placed in the party list. As a result, we have to build an algorithm to determine skip over the next male legislator in the list if there are already too many men.</p><h2 id="post-election-graphics">Post-Election Graphics</h2><p>Another large element of our election coverage was the graphics that we post to social media such as Facebook and Instagram. Because we wanted to be able to generate social media optimized graphics as fast as possible, we needed a method faster than designers plugging in election results into graphic. To achieve this, we built an internal website that would dynamically generate SVGs with the latest data from the Central Election Committee.</p><div class="image-wrap full svelte-5nv82e"><img loading="lazy" alt="Dynamic Graphic Generation" src="https://www.diplateevo.com/images/2020/08/Artboard-7.png" width="100%" class="svelte-5nv82e">  </div><p>To achieve this, designers would first come up with the design of the graphics in the form of an adobe illustrator document. Then we took those graphics and exported each one into a separate SVG. Because SVG files are a XML-based specification, we can port these into our web application in order to make content within the SVG dynamic.</p><p>The great thing about using SVGs in this way is that it is language and tool agnostic, which means you can use whatever existing templating language / framework you use to generate these graphics. In our case, we fitted it into an internal website that the social media team can directly access to download the generated SVG or a PNG format to be posted on social media platforms like Facebook and Instagram.</p><h2 id="monitoring">Monitoring</h2><p>Another critical piece of election-preparedness was making sure that we knew everything that was happening with our web application at all times. To monitor the health of the application and make sure that everything scaled properly, we set up a grafana dashboard that kept track of server errors, response latency, upstream API connections, cache hit ratios, as well as the standard CPU, memory, and database metrics.</p><div class="image-wrap full svelte-5nv82e"><img loading="lazy" alt="Grafana Monitoring" src="https://www.diplateevo.com/images/2020/08/DSC04709.jpg" width="100%" class="svelte-5nv82e">  </div><p>By having the web application directly report metrics to prometheus, it was much easier to get the fine grained metrics specific to elections that we cared about. Because we had taken the time to integrate key metrics into prometheus, when errors began to show up during the election, we were able to immediately know what was causing the error.</p><h2 id="svelte">Svelte</h2><p>Although React has been possibly the most popular front-end framework to use these days, one of the questions I find interesting to ask during interviews is “Under what circumstances is React not a good framework to use? When would you recommend not using React?” This is a question that stumps many less-experienced engineers and people without a good grasp of what React really does in the browser under the hood. In fact, I believe that there are many situations under which React is not a good choice, and building interactives in a news environment is one of them.</p><div class="image-wrap  svelte-5nv82e"><img loading="lazy" alt="svelte logo" src="https://www.diplateevo.com/images/2020/08/svelte.png" width="100%" class="svelte-5nv82e">  </div><p>News organizations have a very different development and deployment cycle than tech companies do, requiring tighter deadlines, faster feedback loops, and more bespoke flexibility. Thus, I decided to use <a href="https://svelte.dev/" target="_blank" rel="noopener noreferrer">Svelte</a>, giving us the following main advantages among many:</p><ul><li>Development speed: Given the amount of work to be done within a short amount of time, I decided that Svelte would be much faster to write than React, giving faster development and feedback times. Using Sapper with Svelte would also allow me to write the server-side data APIs quickly and easily.</li><li>Bundled JS Size: Because Svelte runs as a compiler, it’s able to build and include only the code that your applications needs, making the compiled bundle much smaller than a React application.</li></ul><p>If you’re interested in learning more about Svelte, there are many <a href="https://svelte.dev/tutorial/basics" target="_blank" rel="noopener noreferrer">tutorials to help you get started</a>.</p><h2 id="lessons-learned">Lessons Learned</h2><h3 id="load-test">Load Test</h3><p>The biggest problem we saw on election night was that the site was down for ~1 hour due to high traffic. Specifically, it wasn’t the servers on our end that could not take the traffic, it was our usage of Google Sheets that caused Google to lock our google spreadsheet when the flow of traffic became too large. After Google locked out requests to the spreadsheet, our system started responding to downstream users with 500 errors, causing the entire site to be inoperable.</p><p>The solution was to first disconnect the spreadsheet from our services, which brought both our service and the google spreadsheet back online. Then, we implemented a quick function that would prevent the service from requesting data from the google spreadsheet so often. This brought everything back online.</p><p>The lesson here is that, unless you fully load test your entire system before the election, you never know what problems will be caused when traffic increases by a few orders of magnitude. Often, third-party services such as Google Docs will have their own unwritten throughput and bandwidth limits.</p><h3 id="have-a-clear-incident-response-plan">Have a Clear Incident Response Plan</h3><p>No matter how much planning you do in preparation of the big day, incidents are always likely to happen and things will never go exactly according to plan. That said, after you’ve made all the preparation you can possibly make, the next important thing to plan for is how to respond when things do not go as plan. In our case, by dividing up responsibilities we had a basic level of responsibilities when things went awry, but it would have been more advantageous to rehearse a few scenarios.</p><p>Namely, when the site goes down, it is important to define who will fix the problem and who will report the status to the rest of the team. It is hard for one person to do both, lest the person trying to fix the problem becomes bombarded with too many inquiries about the current status and is unable to concentrate on fixing the problem.</p><h2 id="wrapping-up">Wrapping Up</h2><p>In conclusion, I hope the process we used and the lessons we learned can be built upon by the community, allowing future elections and similar events to be faster, more efficient, and better experiences for our readers and our organizations. I’m sure that our processes will continue to evolve, and I hope we can continue to learn better workflows and collaboration processes.</p>]]></content:encoded>
            <enclosure url="https://www.diplateevo.com/images/2020/08/Artboard-1.png" length="0" type="image/png"/>
        </item>
        <item>
            <title><![CDATA[Memories of New York]]></title>
            <link>https://www.diplateevo.com/memories-of-new-york</link>
            <guid>https://www.diplateevo.com/memories-of-new-york</guid>
            <pubDate>Fri, 08 Mar 2019 00:00:00 GMT</pubDate>
            <description><![CDATA[Next to a stand of dragonfruit, durian, guavas, lychee, and mangosteen on the corner of Main Street and 41st Rd, a nondescript door presents itself in a drab, frosted white.]]></description>
            <content:encoded><![CDATA[<p>Next to a stand of dragonfruit, durian, guavas, lychee, and mangosteen on the corner of Main Street and 41st Rd, a nondescript door presents itself in a drab, frosted white. Above the door the words “Golden Shopping Mall” appear in a golden sans-serif font, which are the only clues that through the door and down the stairs lie culinary gems of New York City.</p><p>Downstairs, you’ll find Tianjin Dumpling House, Lan Zhou Noodles, and the original Xian’s Famous Foods, all cramped into a tiny, poorly ventilated space. We all have our vices – mine include the lamb dumplings from Tianjin Dumpling House, which I’ve always kept a bag of sitting in my freezer. They’re plump, juicy, thicc, and life-changing.</p><p>New York City. A city that has attracted immigrants from around the world for a million different reasons, where a cacophony of languages, cultures, and experiences harmonize. Flushing represents an experience of Asian-America that shares cultural roots yet is different in every other way from my hometown of Cupertino. As I’ve gotten to know Asian-Americans who grew up in Queens, our conversations have uncovered stories of children who had to translate for their parents at a young age or hide in work closets because there wasn’t enough money for childcare.</p><p>My grandparents came to the United States with roughly enough money to buy a dining table and a TV, stopping in Flushing for less than a year before moving to Houston where they live today. In a recent conversation with my grandma, she told me about the restaurant on Main Street where she would buy roast duck during the first six months they spent in the States as they learned English. Today, scenes of the immigrant work ethic are still visible in Flushing, where new immigrants continue to live the life that my grandparents experienced thirty years ago.</p><div class="image-wrap full svelte-5nv82e"><img loading="lazy" alt="Shanghainese Food" src="https://www.diplateevo.com/images/2020/08/IMG_20180210_171604.jpg" width="100%" class="svelte-5nv82e">  </div><p>Down the little alley known as 40th Road is Shanghai You Garden, where they make soup dumplings by hand in the front of the restaurant for all to see, reminding me of Taiwan’s legendary Din Tai Fung. Walk a few doors down and you’ll find Yifang Taiwan Fruit Tea, a gem of Taiwan’s most notorious culinary export: boba.</p><p>There’s no contest when it comes to two types of foods that I will never tire of: noodles and tacos. Despite what the average New Yorker may believe, New York City is a medieval backwater when it comes to tacos – sure you have Los Tacos #1, but anyone who’s had any random taco truck in Los Angeles can tell you that Los Tacos is merely passable in comparison. When it comes to noodles, however, New York’s got an endless variety: Singapore Laksa, Khao Soy, Beef Noodle Soup, Bun Bo Hue, Biang Biang Noodles from places like Tasty Hand Pulled Noodles, Taste Good Malaysian Cuisine, Dun Huang Beef Noodle, and so on.</p><div class="image-wrap full svelte-5nv82e"><img loading="lazy" alt="Filipino Food" src="https://www.diplateevo.com/images/2020/08/IMG_20180624_145920.jpg" width="100%" class="svelte-5nv82e">  </div><p>It’s been almost three months since I’ve left New York City, but I still get flashbacks of the anticipation on 7 train between Mets-Willets Point and Flushing Main St. Or the time that, upon finishing an episode of Parts Unknown at 11pm, my friend and I ventured into the cold for the same living octopus that we just watched Bourdain eat on TV. I’ve tried so many new cuisines in New York City – Sichuan, Colombian, Greek, Uyghur, Tibetan, Brazilian, Malaysian, all without venturing more than a few subway stops from my apartment in Queens.</p><p>I’d love to say that every place I’ve tried in New York has been nothing short of stellar, but the reality is quite the opposite: for every place that has left me with a new appreciation for a certain type of noodle, meat, or vegetable, many others have left me disappointed or unsatisfied. I’ll never understand why New York City has a disproportionately high number of mediocre and expensive ramen restaurants, or the poke shops that are more pleasing to the instagram than the taste buds.</p><p>I think back on it now with a kind of nostalgic Stockholm Syndrome. Faded are the irritations of getting to see sunlight for mere minutes everyday, fighting for personal space on a subway train with a broken AC, and the city noises that never shut up. These days, I’m soaking up all California has to offer by wandering through the desert, the forest, the mountains, or the beaches, wondering how I ever was able to function in such an excessive concrete jungle. The food certainly made it more stomachable.</p>]]></content:encoded>
            <enclosure url="https://www.diplateevo.com/images/2020/08/DSC00224.jpg" length="0" type="image/jpg"/>
        </item>
    </channel>
</rss>